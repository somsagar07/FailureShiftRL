{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import gym\n",
    "import cv2\n",
    "import math\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "        f\"Create an image of a working on a tour plan in a\",\n",
    "        f\"Create an image of a brainstorming new ideas in a\",\n",
    "        f\"Create an image of a actively working on a project in a\",\n",
    "        f\"Create an image of a reflecting on their work in a\",\n",
    "        f\"Create an image of a collaborating with colleagues in a\",\n",
    "        f\"Create an image of a teaching or presenting in a\",\n",
    "        f\"Create an image of a conducting research in a\",\n",
    "        f\"Create an image of a creating an art piece in a\",\n",
    "        f\"Create an image of a solving a complex problem in a\",\n",
    "        f\"Create an image of a giving a speech or a lecture in a\",\n",
    "        f\"Create an image of a experimenting with new techniques in a\"\n",
    "        f\"Create an image of a designing a new invention in a\",\n",
    "        f\"Create an image of a leading a team meeting in a\",\n",
    "        f\"Create an image of a analyzing data on a computer in a\",\n",
    "        f\"Create an image of a writing a book in a\",\n",
    "        f\"Create an image of a gardening in a\",\n",
    "        f\"Create an image of a playing a musical instrument in a\",\n",
    "        f\"Create an image of a practicing yoga in a\",\n",
    "        f\"Create an image of a cooking in a gourmet kitchen in a\",\n",
    "        f\"Create an image of a building a robot in a\",\n",
    "        f\"Create an image of a exploring a historic site in a\"\n",
    "    ]\n",
    "\n",
    "def get_prompt(random):\n",
    "    prompts = [\n",
    "        f\"Create an image of a working on a tour plan in a\",\n",
    "        f\"Create an image of a brainstorming new ideas in a\",\n",
    "        f\"Create an image of a actively working on a project in a\",\n",
    "        f\"Create an image of a reflecting on their work in a\",\n",
    "        f\"Create an image of a collaborating with colleagues in a\",\n",
    "        f\"Create an image of a teaching or presenting in a\",\n",
    "        f\"Create an image of a conducting research in a\",\n",
    "        f\"Create an image of a creating an art piece in a\",\n",
    "        f\"Create an image of a solving a complex problem in a\",\n",
    "        f\"Create an image of a giving a speech or a lecture in a\",\n",
    "        f\"Create an image of a experimenting with new techniques in a\"\n",
    "        f\"Create an image of a designing a new invention in a\",\n",
    "        f\"Create an image of a leading a team meeting in a\",\n",
    "        f\"Create an image of a analyzing data on a computer in a\",\n",
    "        f\"Create an image of a writing a book in a\",\n",
    "        f\"Create an image of a gardening in a\",\n",
    "        f\"Create an image of a playing a musical instrument in a\",\n",
    "        f\"Create an image of a practicing yoga in a\",\n",
    "        f\"Create an image of a cooking in a gourmet kitchen in a\",\n",
    "        f\"Create an image of a building a robot in a\",\n",
    "        f\"Create an image of a exploring a historic site in a\"\n",
    "    ]\n",
    "    return prompts[random]\n",
    "\n",
    "descriptions = ['unique', 'distinctive', 'cool']  \n",
    "professions = ['scientist', 'artist', 'professor']  \n",
    "settings = ['corporate office', 'research center', 'classroom'] \n",
    "\n",
    "def create_prompt(a,b,c, prompt):\n",
    "    sentence = prompt[:21] + descriptions[a] + \" \" + professions[b] + \" \" + prompt[21:] + ' ' +settings[c]+ '.'\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ACTION = 3\n",
    "\n",
    "\n",
    "# Load the model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "clip_model, clip_preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "\n",
    "\n",
    "action_list = {}\n",
    "action_total = {}\n",
    "count = 0\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        for k in range(5):\n",
    "            action_list[count] = 0\n",
    "            action_total[count] = 0\n",
    "            count += 1\n",
    "\n",
    "action_dict = {}\n",
    "count = 0\n",
    "for i in range(NUM_ACTION):\n",
    "    for j in range(NUM_ACTION):\n",
    "        for k in range(NUM_ACTION):\n",
    "            action_dict[count] = (i, j, k)\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(500):\n",
    "    prompt = get_prompt(random.randint(0, 19))\n",
    "    action = random.randint(0,20)\n",
    "\n",
    "    word1, word2, word3 = action_dict[action]\n",
    "    current_word = create_prompt(word1,word2,word3,prompt)\n",
    "\n",
    "    prediction = pipe([current_word]).images\n",
    "\n",
    "    clip_text = clip.tokenize([current_word]).to(device)\n",
    "        \n",
    "    clip_image = clip_preprocess(prediction[0]).unsqueeze(0).to(device)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        image_features = clip_model.encode_image(clip_image)\n",
    "        text_features = clip_model.encode_text(clip_text)\n",
    "\n",
    "    cosine_similarity = torch.nn.functional.cosine_similarity(text_features, image_features, dim=1)\n",
    "    print(f'episode: {i}, similar : {cosine_similarity}')\n",
    "    if cosine_similarity < 0.3:\n",
    "        action_list[action] += 1\n",
    "    action_total[action] +=1   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(action_list)\n",
    "print(action_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epsilon 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.01\n",
    "prob = [1]*20\n",
    "action_list = {}\n",
    "action_total = {}\n",
    "count = 0\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        for k in range(5):\n",
    "            action_list[count] = 0\n",
    "            action_total[count] = 0\n",
    "            count += 1\n",
    "for i in range(500):\n",
    "    prompt_index  = random.choices(range(len(prompts)), prob,k=1)\n",
    "    prompt = prompts[prompt_index[0]]\n",
    "    action = random.randint(0,20)\n",
    "\n",
    "    word1, word2, word3 = action_dict[action]\n",
    "    current_word = create_prompt(word1,word2,word3,prompt)\n",
    "\n",
    "    prediction = pipe([current_word]).images\n",
    "\n",
    "    clip_text = clip.tokenize([current_word]).to(device)\n",
    "        \n",
    "    clip_image = clip_preprocess(prediction[0]).unsqueeze(0).to(device)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        image_features = clip_model.encode_image(clip_image)\n",
    "        text_features = clip_model.encode_text(clip_text)\n",
    "\n",
    "    cosine_similarity = torch.nn.functional.cosine_similarity(text_features, image_features, dim=1)\n",
    "    print(f'episode: {i}, similar : {cosine_similarity}')\n",
    "    if cosine_similarity < 0.3:\n",
    "        action_list[action] += 1\n",
    "        prob[prompt_index[0]]+=epsilon\n",
    "    action_total[action] +=1   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(action_list)\n",
    "print(action_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epsilon 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.1\n",
    "prob = [1]*20\n",
    "action_list = {}\n",
    "action_total = {}\n",
    "count = 0\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        for k in range(5):\n",
    "            action_list[count] = 0\n",
    "            action_total[count] = 0\n",
    "            count += 1\n",
    "for i in range(500):\n",
    "    prompt_index = random.choices(range(len(prompts)), prob,k=1)\n",
    "    prompt = prompts[prompt_index[0]]\n",
    "    action = random.randint(0,20)\n",
    "\n",
    "    word1, word2, word3 = action_dict[action]\n",
    "    current_word = create_prompt(word1,word2,word3,prompt)\n",
    "\n",
    "    prediction = pipe([current_word]).images\n",
    "\n",
    "    clip_text = clip.tokenize([current_word]).to(device)\n",
    "        \n",
    "    clip_image = clip_preprocess(prediction[0]).unsqueeze(0).to(device)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        image_features = clip_model.encode_image(clip_image)\n",
    "        text_features = clip_model.encode_text(clip_text)\n",
    "\n",
    "    cosine_similarity = torch.nn.functional.cosine_similarity(text_features, image_features, dim=1)\n",
    "    print(f'episode: {i}, similar : {cosine_similarity}')\n",
    "    if cosine_similarity < 0.3:\n",
    "        action_list[action] += 1\n",
    "        prob[prompt_index[0]]+=epsilon\n",
    "    action_total[action] +=1   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(action_list)\n",
    "print(action_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epsilon 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.5\n",
    "prob = [1]*20\n",
    "action_list = {}\n",
    "action_total = {}\n",
    "count = 0\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        for k in range(5):\n",
    "            action_list[count] = 0\n",
    "            action_total[count] = 0\n",
    "            count += 1\n",
    "for i in range(500):\n",
    "    prompt_index = random.choices(range(len(prompts)), prob,k=1)\n",
    "    prompt = prompts[prompt_index[0]]\n",
    "    action = random.randint(0,20)\n",
    "\n",
    "    word1, word2, word3 = action_dict[action]\n",
    "    current_word = create_prompt(word1,word2,word3,prompt)\n",
    "\n",
    "    prediction = pipe([current_word]).images\n",
    "\n",
    "    clip_text = clip.tokenize([current_word]).to(device)\n",
    "        \n",
    "    clip_image = clip_preprocess(prediction[0]).unsqueeze(0).to(device)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        image_features = clip_model.encode_image(clip_image)\n",
    "        text_features = clip_model.encode_text(clip_text)\n",
    "\n",
    "    cosine_similarity = torch.nn.functional.cosine_similarity(text_features, image_features, dim=1)\n",
    "    print(f'episode: {i}, similar : {cosine_similarity}')\n",
    "    if cosine_similarity < 0.3:\n",
    "        action_list[action] += 1\n",
    "        prob[prompt_index[0]]+=epsilon\n",
    "    action_total[action] +=1   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(action_list)\n",
    "print(action_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_list = {}\n",
    "action_total = {}\n",
    "count = 0\n",
    "thres = 0\n",
    "prompt = get_prompt(random.randint(0, 19))\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        for k in range(5):\n",
    "            action_list[count] = 0\n",
    "            action_total[count] = 0\n",
    "            count += 1\n",
    "\n",
    "for i in range(500):\n",
    "    \n",
    "    action = random.randint(0,20)\n",
    "\n",
    "    if thres == 5:\n",
    "        prompt = get_prompt(random.randint(0, 19))\n",
    "        \n",
    "    word1, word2, word3 = action_dict[action]\n",
    "    current_word = create_prompt(word1,word2,word3,prompt)\n",
    "\n",
    "    prediction = pipe([current_word]).images\n",
    "\n",
    "    clip_text = clip.tokenize([current_word]).to(device)\n",
    "        \n",
    "    clip_image = clip_preprocess(prediction[0]).unsqueeze(0).to(device)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        image_features = clip_model.encode_image(clip_image)\n",
    "        text_features = clip_model.encode_text(clip_text)\n",
    "\n",
    "    cosine_similarity = torch.nn.functional.cosine_similarity(text_features, image_features, dim=1)\n",
    "    print(f'episode: {i}, similar : {cosine_similarity}')\n",
    "    if cosine_similarity < 0.3:\n",
    "        action_list[action] += 1\n",
    "    else:\n",
    "        thres +=1\n",
    "    action_total[action] +=1   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(action_list)\n",
    "print(action_total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
