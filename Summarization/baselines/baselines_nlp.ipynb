{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/local/ASURITE/bpathir1/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/local/ASURITE/bpathir1/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/local/ASURITE/bpathir1/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/local/ASURITE/bpathir1/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "from random import randint\n",
    "from pattern.en import pluralize, singularize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def drop_stop_words(sentence):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(sentence)\n",
    "    filtered_sentence = [word for word in word_tokens if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_sentence)\n",
    "\n",
    "def remove_punctuation(sentence):\n",
    "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "    return sentence\n",
    "\n",
    "def to_lowercase(sentence):\n",
    "    return sentence.lower()\n",
    "\n",
    "def negate_sentence(sentence):\n",
    "    negation_words = ['not', 'no', 'never', 'none', 'nothing', 'nobody', 'neither', 'nowhere', 'hardly', 'scarcely', 'barely', 'don’t', 'isn’t', 'wasn’t', 'shouldn’t', 'wouldn’t', 'couldn’t', 'won’t', 'can’t', 'doesn’t']\n",
    "    word_tokens = word_tokenize(sentence)\n",
    "    negated_sentence = []\n",
    "    negated = False\n",
    "\n",
    "    for word in word_tokens:\n",
    "        if word in negation_words:\n",
    "            negated = not negated\n",
    "            continue\n",
    "        negated_sentence.append(\"not \" + word if negated else word)\n",
    "\n",
    "    return ' '.join(negated_sentence)\n",
    "\n",
    "def return_random_number(begin, end):\n",
    "    return randint(begin, end)\n",
    "\n",
    "def delete_random_character(sentence):\n",
    "    \"\"\"\n",
    "    This function takes a sentence, randomly selects a word, then randomly deletes a character from it.\n",
    "    \"\"\"\n",
    "    sample_tokenized = nltk.word_tokenize(sentence)\n",
    "\n",
    "    # Select a random word\n",
    "    random_word_index = 0\n",
    "    random_word_selected = False\n",
    "\n",
    "    while not random_word_selected:\n",
    "        random_word_index = return_random_number(0, len(sample_tokenized)-1)\n",
    "        if len(sample_tokenized[random_word_index]) > 2:\n",
    "            random_word_selected = True\n",
    "\n",
    "    selected_word = sample_tokenized[random_word_index]\n",
    "\n",
    "    # Delete a random character\n",
    "    random_char_index = return_random_number(1, len(selected_word)-2)\n",
    "    perturbed_word = selected_word[:random_char_index] + selected_word[random_char_index+1:]\n",
    "\n",
    "    # Reconstruct the perturbed sample\n",
    "    perturbed_sample = \" \".join(sample_tokenized[:random_word_index] + [perturbed_word] + sample_tokenized[random_word_index+1:])\n",
    "\n",
    "    return perturbed_sample\n",
    "\n",
    "def insert_random_character(sentence):\n",
    "    \"\"\"\n",
    "    This function takes a sentence, randomly selects a word, then randomly inserts a character into it.\n",
    "    \"\"\"\n",
    "    sample_tokenized = nltk.word_tokenize(sentence)\n",
    "\n",
    "    # Select a random word\n",
    "    random_word_index = 0\n",
    "    random_word_selected = False\n",
    "\n",
    "    while not random_word_selected:\n",
    "        random_word_index = return_random_number(0, len(sample_tokenized)-1)\n",
    "        if len(sample_tokenized[random_word_index]) > 2:\n",
    "            random_word_selected = True\n",
    "\n",
    "    selected_word = sample_tokenized[random_word_index]\n",
    "\n",
    "    # Insert a random character\n",
    "    random_char_index = return_random_number(1, len(selected_word)-1)\n",
    "    random_char_code = return_random_number(97, 122)\n",
    "    random_char = chr(random_char_code)\n",
    "\n",
    "    perturbed_word = selected_word[:random_char_index] + random_char + selected_word[random_char_index:]\n",
    "\n",
    "    # Reconstruct the perturbed sample\n",
    "    perturbed_sample = \" \".join(sample_tokenized[:random_word_index] + [perturbed_word] + sample_tokenized[random_word_index+1:])\n",
    "\n",
    "    return perturbed_sample\n",
    "\n",
    "def random_changing_type():\n",
    "    return 'FirstChar' if randint(1, 2) == 1 else 'AllChars'\n",
    "\n",
    "def change_letter_case(sentence):\n",
    "    \"\"\"\n",
    "    This function takes a sentence, randomly selects a word, then changes the case of the first character\n",
    "    or all characters in that word.\n",
    "    \"\"\"\n",
    "    sample_tokenized = nltk.word_tokenize(sentence)\n",
    "\n",
    "    # Select a random word\n",
    "    random_word_index = 0\n",
    "    random_word_selected = False\n",
    "\n",
    "    while not random_word_selected:\n",
    "        random_word_index = return_random_number(0, len(sample_tokenized)-1)\n",
    "        if len(sample_tokenized[random_word_index]) > 2:\n",
    "            random_word_selected = True\n",
    "\n",
    "    selected_word = sample_tokenized[random_word_index]\n",
    "\n",
    "    # Change the letter case\n",
    "    change_type = random_changing_type()\n",
    "    temp_word = \"\"\n",
    "\n",
    "    if change_type == 'FirstChar':\n",
    "        # Toggle case of the first character\n",
    "        char = selected_word[0]\n",
    "        temp_word = char.lower() if char.isupper() else char.upper()\n",
    "        temp_word += selected_word[1:]\n",
    "    elif change_type == 'AllChars':\n",
    "        # Toggle case of all characters\n",
    "        for char in selected_word:\n",
    "            temp_word += char.lower() if char.isupper() else char.upper()\n",
    "\n",
    "    # Reconstruct the perturbed sample\n",
    "    perturbed_sample = \" \".join(sample_tokenized[:random_word_index] + [temp_word] + sample_tokenized[random_word_index+1:])\n",
    "\n",
    "    return perturbed_sample\n",
    "\n",
    "def generate_misspelling(word):\n",
    "    \"\"\"\n",
    "    This function takes a word and generates a misspelling by randomly altering a character.\n",
    "    \"\"\"\n",
    "    if len(word) > 1:\n",
    "        random_char_index = return_random_number(0, len(word) - 1)\n",
    "        random_char_code = return_random_number(97, 122)\n",
    "        random_char = chr(random_char_code)\n",
    "\n",
    "        misspelled_word = word[:random_char_index] + random_char + word[random_char_index+1:]\n",
    "        return misspelled_word\n",
    "    else:\n",
    "        return word\n",
    "\n",
    "def apply_misspellings(sentence, max_perturb=10):\n",
    "    \"\"\"\n",
    "    This function takes a sentence and applies misspelling perturbations by randomly altering characters in words.\n",
    "    \"\"\"\n",
    "    sample_tokenized = nltk.word_tokenize(sentence)\n",
    "    perturbed_sample = sentence\n",
    "    word_replaced = False\n",
    "\n",
    "    num_replacements = 0\n",
    "    while num_replacements < min(max_perturb, len(sample_tokenized)):\n",
    "        random_word_index = return_random_number(0, len(sample_tokenized) - 1)\n",
    "        selected_word = sample_tokenized[random_word_index]\n",
    "\n",
    "        misspelled_word = generate_misspelling(selected_word)\n",
    "\n",
    "        if misspelled_word != selected_word:\n",
    "            perturbed_sample = perturbed_sample.replace(selected_word, misspelled_word, 1)\n",
    "            num_replacements += 1\n",
    "            word_replaced = True\n",
    "\n",
    "    return perturbed_sample if word_replaced else sentence\n",
    "\n",
    "def repeat_random_character(sentence):\n",
    "    \"\"\"\n",
    "    This function takes a sentence, randomly selects a word, then randomly repeats a character in that word.\n",
    "    \"\"\"\n",
    "    sample_tokenized = nltk.word_tokenize(sentence)\n",
    "\n",
    "    # Select a random word\n",
    "    random_word_index = 0\n",
    "    random_word_selected = False\n",
    "\n",
    "    while not random_word_selected:\n",
    "        random_word_index = return_random_number(0, len(sample_tokenized)-1)\n",
    "        if len(sample_tokenized[random_word_index]) > 2:\n",
    "            random_word_selected = True\n",
    "\n",
    "    selected_word = sample_tokenized[random_word_index]\n",
    "\n",
    "    # Repeat a random character\n",
    "    random_char_index = return_random_number(1, len(selected_word)-2)\n",
    "    repeated_char = selected_word[random_char_index]\n",
    "\n",
    "    perturbed_word = selected_word[:random_char_index] + repeated_char + selected_word[random_char_index:]\n",
    "\n",
    "    # Reconstruct the perturbed sample\n",
    "    perturbed_sample = \" \".join(sample_tokenized[:random_word_index] + [perturbed_word] + sample_tokenized[random_word_index+1:])\n",
    "\n",
    "    return perturbed_sample\n",
    "\n",
    "def return_adjacent_char(input_char):\n",
    "\n",
    "    if (input_char == 'a'):\n",
    "        return 's'\n",
    "\n",
    "    elif (input_char == 'b'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'v'\n",
    "        else:\n",
    "            return 'n'\n",
    "\n",
    "    elif (input_char == 'c'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'x'\n",
    "        else:\n",
    "            return 'v'\n",
    "\n",
    "    elif (input_char == 'd'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 's'\n",
    "        else:\n",
    "            return 'f'\n",
    "\n",
    "    elif (input_char == 'e'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'w'\n",
    "        else:\n",
    "            return 'r'\n",
    "\n",
    "    elif (input_char == 'f'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'd'\n",
    "        else:\n",
    "            return 'g'\n",
    "\n",
    "    elif (input_char == 'g'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'f'\n",
    "        else:\n",
    "            return 'h'\n",
    "\n",
    "    elif (input_char == 'h'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'g'\n",
    "        else:\n",
    "            return 'j'\n",
    "\n",
    "    elif (input_char == 'i'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'u'\n",
    "        else:\n",
    "            return 'o'\n",
    "\n",
    "    elif (input_char == 'j'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'h'\n",
    "        else:\n",
    "            return 'k'\n",
    "\n",
    "    elif (input_char == 'k'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'j'\n",
    "        else:\n",
    "            return 'l'\n",
    "\n",
    "    elif (input_char == 'l'):\n",
    "        return 'k'\n",
    "\n",
    "    elif (input_char == 'm'):\n",
    "        return 'n'\n",
    "\n",
    "    elif (input_char == 'n'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'b'\n",
    "        else:\n",
    "            return 'm'\n",
    "\n",
    "    elif (input_char == 'o'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'i'\n",
    "        else:\n",
    "            return 'p'\n",
    "\n",
    "    elif (input_char == 'p'):\n",
    "        return 'o'\n",
    "\n",
    "    elif (input_char == 'q'):\n",
    "        return 'w'\n",
    "\n",
    "    elif (input_char == 'r'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'e'\n",
    "        else:\n",
    "            return 't'\n",
    "\n",
    "    elif (input_char == 's'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'a'\n",
    "        else:\n",
    "            return 'd'\n",
    "\n",
    "    elif (input_char == 't'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'r'\n",
    "        else:\n",
    "            return 'y'\n",
    "\n",
    "    elif (input_char == 'u'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'y'\n",
    "        else:\n",
    "            return 'i'\n",
    "\n",
    "    elif (input_char == 'v'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'c'\n",
    "        else:\n",
    "            return 'b'\n",
    "\n",
    "    elif (input_char == 'w'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'q'\n",
    "        else:\n",
    "            return 'e'\n",
    "\n",
    "    elif (input_char == 'x'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'z'\n",
    "        else:\n",
    "            return 'c'\n",
    "\n",
    "    elif (input_char == 'y'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 't'\n",
    "        else:\n",
    "            return 'u'\n",
    "\n",
    "    elif (input_char == 'z'):\n",
    "        return 'x'\n",
    "    #---------------------------------------------\n",
    "    elif (input_char == 'A'):\n",
    "        return 'S'\n",
    "\n",
    "    elif (input_char == 'B'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'V'\n",
    "        else:\n",
    "            return 'N'\n",
    "\n",
    "    elif (input_char == 'C'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'X'\n",
    "        else:\n",
    "            return 'V'\n",
    "\n",
    "    elif (input_char == 'D'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'S'\n",
    "        else:\n",
    "            return 'F'\n",
    "\n",
    "    elif (input_char == 'E'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'W'\n",
    "        else:\n",
    "            return 'R'\n",
    "\n",
    "    elif (input_char == 'F'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'D'\n",
    "        else:\n",
    "            return 'G'\n",
    "\n",
    "    elif (input_char == 'G'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'F'\n",
    "        else:\n",
    "            return 'H'\n",
    "\n",
    "    elif (input_char == 'H'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'G'\n",
    "        else:\n",
    "            return 'J'\n",
    "\n",
    "    elif (input_char == 'I'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'U'\n",
    "        else:\n",
    "            return 'O'\n",
    "\n",
    "    elif (input_char == 'J'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'H'\n",
    "        else:\n",
    "            return 'K'\n",
    "\n",
    "    elif (input_char == 'K'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'J'\n",
    "        else:\n",
    "            return 'L'\n",
    "\n",
    "    elif (input_char == 'L'):\n",
    "        return 'K'\n",
    "\n",
    "    elif (input_char == 'M'):\n",
    "        return 'N'\n",
    "\n",
    "    elif (input_char == 'N'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'B'\n",
    "        else:\n",
    "            return 'M'\n",
    "\n",
    "    elif (input_char == 'O'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'I'\n",
    "        else:\n",
    "            return 'P'\n",
    "\n",
    "    elif (input_char == 'P'):\n",
    "        return 'O'\n",
    "\n",
    "    elif (input_char == 'Q'):\n",
    "        return 'W'\n",
    "\n",
    "    elif (input_char == 'R'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'E'\n",
    "        else:\n",
    "            return 'T'\n",
    "\n",
    "    elif (input_char == 'S'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'A'\n",
    "        else:\n",
    "            return 'D'\n",
    "\n",
    "    elif (input_char == 'T'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'R'\n",
    "        else:\n",
    "            return 'Y'\n",
    "\n",
    "    elif (input_char == 'U'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'Y'\n",
    "        else:\n",
    "            return 'I'\n",
    "\n",
    "    elif (input_char == 'V'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'C'\n",
    "        else:\n",
    "            return 'B'\n",
    "\n",
    "    elif (input_char == 'W'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'Q'\n",
    "        else:\n",
    "            return 'E'\n",
    "\n",
    "    elif (input_char == 'X'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'Z'\n",
    "        else:\n",
    "            return 'C'\n",
    "\n",
    "    elif (input_char == 'Y'):\n",
    "        which_adjacent = return_random_number(1, 2)\n",
    "        if (which_adjacent == 1):\n",
    "            return 'T'\n",
    "        else:\n",
    "            return 'U'\n",
    "\n",
    "    elif (input_char == 'Z'):\n",
    "        return 'X'\n",
    "\n",
    "    else:\n",
    "        return '*'\n",
    "\n",
    "def replace_with_adjacent_character(sentence):\n",
    "    \"\"\"\n",
    "    This function takes a sentence, randomly selects a word, then randomly replaces a character in that word.\n",
    "    \"\"\"\n",
    "    sample_tokenized = nltk.word_tokenize(sentence)\n",
    "\n",
    "    # Select a random word\n",
    "    random_word_index = 0\n",
    "    random_word_selected = False\n",
    "\n",
    "    while not random_word_selected:\n",
    "        random_word_index = return_random_number(0, len(sample_tokenized)-1)\n",
    "        if len(sample_tokenized[random_word_index]) > 2:\n",
    "            random_word_selected = True\n",
    "\n",
    "    selected_word = sample_tokenized[random_word_index]\n",
    "\n",
    "    # Replace a random character\n",
    "    random_char_index = return_random_number(1, len(selected_word)-2)\n",
    "    char_to_replace = selected_word[random_char_index]\n",
    "    adjacent_char = return_adjacent_char(char_to_replace)\n",
    "\n",
    "    perturbed_word = selected_word[:random_char_index] + adjacent_char + selected_word[random_char_index+1:]\n",
    "\n",
    "    # Reconstruct the perturbed sample\n",
    "    perturbed_sample = \" \".join(sample_tokenized[:random_word_index] + [perturbed_word] + sample_tokenized[random_word_index+1:])\n",
    "\n",
    "    return perturbed_sample\n",
    "\n",
    "def swap_characters(input_word, position, adjacent):\n",
    "    temp_word = ''\n",
    "    if (adjacent == 'left'):\n",
    "        if (position == 1):\n",
    "            temp_word = input_word[1]\n",
    "            temp_word += input_word[0]\n",
    "            temp_word += input_word[2:]\n",
    "        elif (position == len(input_word)-1):\n",
    "            temp_word = input_word[0:position-1]\n",
    "            temp_word += input_word[position]\n",
    "            temp_word += input_word[position-1]\n",
    "        elif (position > 1 and position < len(input_word)-1):\n",
    "            temp_word = input_word[0:position-1]\n",
    "            temp_word += input_word[position]\n",
    "            temp_word += input_word[position-1]\n",
    "            temp_word += input_word[position+1:]\n",
    "\n",
    "    elif (adjacent == 'right'):\n",
    "        if (position == 0):\n",
    "            temp_word = input_word[1]\n",
    "            temp_word += input_word[0]\n",
    "            temp_word += input_word[2:]\n",
    "        elif (position == len(input_word)-2):\n",
    "            temp_word = input_word[0:position]\n",
    "            temp_word += input_word[position+1]\n",
    "            temp_word += input_word[position]\n",
    "        elif (position > 0 and position < len(input_word)-2):\n",
    "            temp_word = input_word[0:position]\n",
    "            temp_word += input_word[position+1]\n",
    "            temp_word += input_word[position]\n",
    "            temp_word += input_word[position+2:]\n",
    "\n",
    "    return temp_word\n",
    "\n",
    "def swap_random_character(sentence):\n",
    "    \"\"\"\n",
    "    This function takes a sentence, randomly selects a word, then randomly swaps a character in that word with its adjacent character.\n",
    "    \"\"\"\n",
    "    sample_tokenized = nltk.word_tokenize(sentence)\n",
    "\n",
    "    # Select a random word\n",
    "    random_word_index = 0\n",
    "    random_word_selected = False\n",
    "\n",
    "    while not random_word_selected:\n",
    "        random_word_index = return_random_number(0, len(sample_tokenized)-1)\n",
    "        if len(sample_tokenized[random_word_index]) > 2:\n",
    "            random_word_selected = True\n",
    "\n",
    "    selected_word = sample_tokenized[random_word_index]\n",
    "\n",
    "    # Select a random character and its adjacent for swapping\n",
    "    random_char_index = return_random_number(0, len(selected_word)-1)\n",
    "    adjacent_for_swapping = 'right' if random_char_index == 0 else 'left' if random_char_index == len(selected_word)-1 else 'left' if return_random_number(1, 2) == 1 else 'right'\n",
    "\n",
    "    # Swap the character and the adjacent\n",
    "    perturbed_word = swap_characters(selected_word, random_char_index, adjacent_for_swapping)\n",
    "\n",
    "    # Reconstruct the perturbed sample\n",
    "    perturbed_sample = \" \".join(sample_tokenized[:random_word_index] + [perturbed_word] + sample_tokenized[random_word_index+1:])\n",
    "\n",
    "    return perturbed_sample\n",
    "\n",
    "def delete_random_word(sentence):\n",
    "    \"\"\"\n",
    "    This function takes a sentence, tokenizes it, and randomly deletes one of the words.\n",
    "    \"\"\"\n",
    "    sample_tokenized = nltk.word_tokenize(sentence)\n",
    "\n",
    "    # Select a random word to delete\n",
    "    random_word_index = return_random_number(0, len(sample_tokenized)-1)\n",
    "\n",
    "    # Ensure the selected word has more than one character (optional, can be adjusted)\n",
    "    while len(sample_tokenized[random_word_index]) <= 1:\n",
    "        random_word_index = return_random_number(0, len(sample_tokenized)-1)\n",
    "\n",
    "    # Delete the word and reconstruct the sentence\n",
    "    del sample_tokenized[random_word_index]\n",
    "    perturbed_sample = \" \".join(sample_tokenized)\n",
    "\n",
    "    return perturbed_sample\n",
    "\n",
    "\n",
    "def change_ordering(input_length, input_side, input_changes):\n",
    "    ordering = []\n",
    "\n",
    "    if (input_side == 1):\n",
    "        for i in range(0, input_length):\n",
    "            if (i < input_changes):\n",
    "\n",
    "                candidates=[]\n",
    "                for j in range(0, input_changes):\n",
    "                    if (j != i and j not in ordering):\n",
    "                        candidates.append(j)\n",
    "\n",
    "                if (len(candidates) > 0):\n",
    "                    random_index = return_random_number(0, len(candidates)-1)\n",
    "                    ordering.append(candidates[random_index])\n",
    "                else:\n",
    "                    ordering.append(i)\n",
    "            else:\n",
    "                ordering.append(i)\n",
    "\n",
    "    elif (input_side == 2):\n",
    "        for i in range(0, input_length):\n",
    "            if (i < input_length-input_changes):\n",
    "                ordering.append(i)\n",
    "\n",
    "            else:\n",
    "                candidates=[]\n",
    "                for j in range(input_length-input_changes, input_length):\n",
    "                    if (j != i and j not in ordering):\n",
    "                        candidates.append(j)\n",
    "\n",
    "                if (len(candidates) > 0):\n",
    "                    random_index = return_random_number(0, len(candidates)-1)\n",
    "                    ordering.append(candidates[random_index])\n",
    "                else:\n",
    "                    ordering.append(i)\n",
    "\n",
    "    return ordering\n",
    "\n",
    "def perturb_word_order(sentence):\n",
    "    \"\"\"\n",
    "    This function takes a sentence, tokenizes it, and randomly changes the order of the words.\n",
    "    \"\"\"\n",
    "    sample_tokenized = nltk.word_tokenize(sentence)\n",
    "\n",
    "    perturbed_sample = \"\"\n",
    "    if len(sample_tokenized) > 3:\n",
    "        last_token = \"\"\n",
    "        if sample_tokenized[-1] in ('.', '?', '!', ';', ','):\n",
    "            last_token = sample_tokenized[-1]\n",
    "            sample_tokenized = sample_tokenized[:-1]\n",
    "\n",
    "        ordering_side = return_random_number(1, 2)\n",
    "        num_changed_words = return_random_number(2, len(sample_tokenized)-1)\n",
    "        new_word_order = change_ordering(len(sample_tokenized), ordering_side, num_changed_words)\n",
    "\n",
    "        for i in new_word_order:\n",
    "            perturbed_sample += sample_tokenized[i] + ' '\n",
    "        perturbed_sample += last_token\n",
    "    else:\n",
    "        perturbed_sample = sentence\n",
    "\n",
    "    return perturbed_sample\n",
    "\n",
    "def repeat_random_word(sentence):\n",
    "    \"\"\"\n",
    "    This function takes a sentence, tokenizes it, and randomly repeats one of the words.\n",
    "    \"\"\"\n",
    "    sample_tokenized = nltk.word_tokenize(sentence)\n",
    "\n",
    "    # Select a random word to repeat\n",
    "    random_word_index = return_random_number(0, len(sample_tokenized)-1)\n",
    "\n",
    "    # Ensure the selected word has more than one character (optional, can be adjusted)\n",
    "    while len(sample_tokenized[random_word_index]) <= 1:\n",
    "        random_word_index = return_random_number(0, len(sample_tokenized)-1)\n",
    "\n",
    "    selected_word = sample_tokenized[random_word_index]\n",
    "\n",
    "    # Reconstruct the sentence with the repeated word\n",
    "    perturbed_sample = \" \".join(sample_tokenized[:random_word_index+1] + [selected_word] + sample_tokenized[random_word_index+1:])\n",
    "\n",
    "    return perturbed_sample\n",
    "\n",
    "def toggle_singular_plural(sentence):\n",
    "    \"\"\"\n",
    "    This function takes a sentence, tokenizes it, and randomly changes one of the words from singular to plural or vice versa.\n",
    "    \"\"\"\n",
    "    sample_tokenized = nltk.word_tokenize(sentence)\n",
    "\n",
    "    # Select a random word\n",
    "    random_word_index = return_random_number(0, len(sample_tokenized)-1)\n",
    "\n",
    "    selected_word = sample_tokenized[random_word_index]\n",
    "    word_synsets = wordnet.synsets(selected_word)\n",
    "\n",
    "    # Check if the word is likely a noun (this is a simplification and might not always be accurate)\n",
    "    if word_synsets and word_synsets[0].pos() in ['n', 's']:\n",
    "        if pluralize(singularize(selected_word)) == selected_word:  # If the word is singular\n",
    "            new_word = pluralize(selected_word)\n",
    "        else:  # If the word is plural\n",
    "            new_word = singularize(selected_word)\n",
    "\n",
    "        sample_tokenized[random_word_index] = new_word\n",
    "\n",
    "    # Reconstruct the sentence\n",
    "    perturbed_sample = \" \".join(sample_tokenized)\n",
    "\n",
    "    return perturbed_sample\n",
    "\n",
    "def is_third_person(input_pos_tag):\n",
    "    subject = ''\n",
    "    for i in range(0, len(input_pos_tag)):\n",
    "        token = input_pos_tag[i]\n",
    "        if (subject == ''):\n",
    "            if (token[0].lower() in ('it', 'this', 'that', 'he', 'she')):\n",
    "                subject = 'third person'\n",
    "            elif (token[1] in ('NNP')):\n",
    "                subject = 'third person'\n",
    "            elif (token[0].lower() in ('i', 'we', 'you', 'they', 'she', 'these', 'those')):\n",
    "                subject = 'not third person'\n",
    "            elif (token[0].lower() in ('NNPS')):\n",
    "                subject = 'not third person'\n",
    "    if (subject == 'third person'):\n",
    "        return 'third person'\n",
    "    elif (subject == 'not third person'):\n",
    "        return 'not third person'\n",
    "    else:\n",
    "        return 'none'\n",
    "\n",
    "def change_verb_tense(sentence):\n",
    "    \"\"\"\n",
    "    This function takes a sentence and changes the tense of verbs found in the sentence.\n",
    "    \"\"\"\n",
    "    sample_tokenized = nltk.word_tokenize(sentence)\n",
    "    sample_pos_tag = nltk.pos_tag(sample_tokenized)\n",
    "\n",
    "    # ... [Include the rest of the verb tense changing logic from your original script here] ...\n",
    "\n",
    "    # Reconstruct the perturbed sample\n",
    "    perturbed_sample = \" \".join([token for token, _ in sample_pos_tag])\n",
    "\n",
    "    return perturbed_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartModel\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Falconsai/text_summarization\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Falconsai/text_summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The renowned scientist, after years of groundbreaking research, presented her findings at the international conference, emphasizing the urgent need for immediate action to combat climate change. Furthermore, she highlighted the critical role of innovative technologies in sustainable development and called for increased international collaboration to foster a global response to environmental issues.\n"
     ]
    }
   ],
   "source": [
    "def get_summary(text, max_length=130, min_length=40):\n",
    "    # Encode the input text and add the special tokens for the model\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", truncation=True)\n",
    "\n",
    "    # Generate summary with the model\n",
    "    summary_ids = model.generate(inputs, max_length=max_length, min_length=min_length, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "\n",
    "    # Decode and return the summary\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your example sentence HERE .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_list_1 = [\n",
    "    drop_stop_words,\n",
    "    remove_punctuation,\n",
    "    to_lowercase,\n",
    "    negate_sentence,\n",
    "    delete_random_character,\n",
    "    insert_random_character,\n",
    "    change_letter_case,\n",
    "    apply_misspellings,\n",
    "    repeat_random_character,\n",
    "    replace_with_adjacent_character,\n",
    "    swap_random_character,\n",
    "    delete_random_word,\n",
    "    perturb_word_order,\n",
    "    repeat_random_word,\n",
    "    toggle_singular_plural,\n",
    "    change_verb_tense\n",
    "]\n",
    "action_list_name = [\n",
    "  'drop_stop_words',\n",
    "  'remove_punctuation',\n",
    "  'to_lowercase',\n",
    "  'negate_sentence',\n",
    "  'delete_random_character',\n",
    "  'insert_random_character',\n",
    "  'change_letter_case',\n",
    "  'apply_misspellings',\n",
    "  'repeat_random_character',\n",
    "  'replace_with_adjacent_character',\n",
    "  'swap_random_character',\n",
    "  'delete_random_word',\n",
    "  'perturb_word_order',\n",
    "  'repeat_random_word',\n",
    "  'toggle_singular_plural',\n",
    "  'change_verb_tense'\n",
    "]\n",
    "\n",
    "sentence = \"Your example sentence here.\"\n",
    "index = 6\n",
    "action_list_1[index](sentence)\n",
    "\n",
    "dataset = load_dataset(\"openai/summarize_from_feedback\", 'axis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 7.955891555490761\n"
     ]
    }
   ],
   "source": [
    "import sacrebleu\n",
    "\n",
    "def calculate_bleu_score(candidate, reference):\n",
    "    \"\"\"\n",
    "    Calculate the BLEU score for a candidate sentence given a reference sentence.\n",
    "\n",
    "    Args:\n",
    "    candidate (str): The summarized text (candidate translation).\n",
    "    reference (str): The reference text (reference translation).\n",
    "\n",
    "    Returns:\n",
    "    float: The BLEU score.\n",
    "    \"\"\"\n",
    "    bleu = sacrebleu.corpus_bleu([candidate], [[reference]])\n",
    "    return bleu.score\n",
    "\n",
    "candidate_summary = \"The scientist presented her climate change research at a conference, calling for urgent action.\"\n",
    "reference_summary = \"At the conference, the scientist highlighted the need for immediate measures against climate change.\"\n",
    "\n",
    "bleu_score = calculate_bleu_score(candidate_summary, reference_summary)\n",
    "print(f\"BLEU Score: {bleu_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_list = {}\n",
    "action_total = {}\n",
    "count = 0\n",
    "for i in range(16):\n",
    "    action_list[count] = 0\n",
    "    action_total[count] = 0\n",
    "    count += 1\n",
    "    \n",
    "for i in range(500):\n",
    "    random_index = random.randint(0, len(dataset['test']['info']) - 1)\n",
    "    current_word = dataset['test']['info'][random_index]['article'][:3400]\n",
    "    action = random.randint(0,15)\n",
    "    prediction = action_list_1[action](current_word)\n",
    "    score = calculate_bleu_score(current_word, get_summary(prediction))\n",
    "    print(f'action: {action},score: {score}')\n",
    "    if score < 10:\n",
    "        action_list[action] +=1\n",
    "    action_total[action] +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## epsilon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_values = [0.01, 0.1, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability = [1]*6312\n",
    "epsilon = epsilon_values[0]\n",
    "ep1_action_list = {}\n",
    "ep1_action_total = {}\n",
    "count = 0\n",
    "for i in range(16):\n",
    "    ep1_action_list[count] = 0\n",
    "    ep1_action_total[count] = 0\n",
    "    count += 1\n",
    "\n",
    "for i in range(500):\n",
    "    random_index = random.choices(range(len(dataset['test']['info'])), probability,k=1)\n",
    "    current_word = dataset['test']['info'][random_index[0]]['article'][:3400]\n",
    "    action = random.randint(0,15)\n",
    "    prediction = action_list[action](current_word)\n",
    "    score = calculate_bleu_score(current_word, get_summary(prediction))\n",
    "    print(f'action: {action},score: {score}')\n",
    "    if score < 10:\n",
    "        ep1_action_list[action] +=1\n",
    "        probability[random_index[0]] += epsilon\n",
    "    ep1_action_total[action] +=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
